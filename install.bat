@echo off
echo Downloading the wget binaries...
curl -L -o wget.exe https://github.com/fabiomatricardi/VisualAI-4ALL/raw/main/wget.exe
echo Downloading the LlamaCPP binaries...
wget.exe https://github.com/ggml-org/llama.cpp/releases/download/b5535/llama-b5535-bin-win-vulkan-x64.zip -nv --show-progress
wget.exe https://github.com/fabiomatricardi/VisualAI-4ALL/raw/main/server.bat -nv --show-progress
echo Downloading the Language model...
wget https://hf-mirror.com/ggml-org/InternVL2_5-1B-GGUF/resolve/main/InternVL2_5-1B-Q8_0.gguf -nv --show-progress
echo Downloading the Visual Encoder...
wget https://hf-mirror.com/ggml-org/InternVL2_5-1B-GGUF/resolve/main/mmproj-InternVL2_5-1B-Q8_0.gguf -nv --show-progress
echo Unzipping the llama.cpp binaries...
tar -xf llama-b5535-bin-win-vulkan-x64.zip
echo Starting llama-server with 8192 tokens context window...
start cmd.exe /c llama-server.exe -m InternVL2_5-1B-Q8_0.gguf --mmproj mmproj-InternVL2_5-1B-Q8_0.gguf -ngl 0
echo Opening default browser in 10 seconds...
timeout /t 10
start http://localhost:8080
